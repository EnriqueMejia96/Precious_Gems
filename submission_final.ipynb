{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "728ebb49",
   "metadata": {},
   "source": [
    "# ENIGMA TECH TATVA 2020 - KAGGLE COMPETITIONS\n",
    "### PERSONAL SUBMISSION\n",
    "- [1. DOWNLOAD DATA](#1)\n",
    "- [2. CREATE TRAIN/VAL DATASET](#2)\n",
    "- [3. DATA NORMALIZATION](#3)\n",
    "- [4. ONE-HOT ENCODING](#4)\n",
    "- [5. CREATE DATASET (TensorFlow)](#5)\n",
    "- [6. CREATE PERSONAL CALLBACK](#6)\n",
    "- [7. BUILD AND COMPILE THE MODEL](#7)\n",
    "- [8. FIT THE MODEL](#8)\n",
    "- [9. SAVE THE BEST RESULT](#9)\n",
    "- [10. GENERATE ASSIGMENT](#10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "k0x8i_3Jxo7J",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 60770,
     "status": "ok",
     "timestamp": 1665873196366,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "k0x8i_3Jxo7J",
    "outputId": "9facf879-ec98-40da-fa31-a69d5deedce2"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading package lists... Done\n",
      "Building dependency tree       \n",
      "Reading state information... Done\n",
      "The following package was automatically installed and is no longer required:\n",
      "  libnvidia-common-460\n",
      "Use 'apt autoremove' to remove it.\n",
      "The following packages will be REMOVED:\n",
      "  libcudnn8-dev\n",
      "The following held packages will be changed:\n",
      "  libcudnn8\n",
      "The following packages will be upgraded:\n",
      "  libcudnn8\n",
      "1 upgraded, 0 newly installed, 1 to remove and 10 not upgraded.\n",
      "Need to get 420 MB of archives.\n",
      "After this operation, 1,622 MB disk space will be freed.\n",
      "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  libcudnn8 8.4.1.50-1+cuda11.6 [420 MB]\n",
      "Fetched 420 MB in 13s (32.9 MB/s)\n",
      "(Reading database ... 123934 files and directories currently installed.)\n",
      "Removing libcudnn8-dev (8.1.1.33-1+cuda11.2) ...\n",
      "update-alternatives: removing manually selected alternative - switching libcudnn to auto mode\n",
      "(Reading database ... 123911 files and directories currently installed.)\n",
      "Preparing to unpack .../libcudnn8_8.4.1.50-1+cuda11.6_amd64.deb ...\n",
      "Unpacking libcudnn8 (8.4.1.50-1+cuda11.6) over (8.1.1.33-1+cuda11.2) ...\n",
      "Setting up libcudnn8 (8.4.1.50-1+cuda11.6) ...\n"
     ]
    }
   ],
   "source": [
    "# Install this package to use Colab's GPU for training\n",
    "!apt install --allow-change-held-packages libcudnn8=8.4.1.50-1+cuda11.6"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9a844c6",
   "metadata": {
    "id": "26b1abdf"
   },
   "source": [
    "## Also you can download the train.csv file from:\n",
    "https://www.kaggle.com/competitions/enigma-tech-tatva-2022/data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1e15aeb",
   "metadata": {},
   "source": [
    "<a name='1'></a>\n",
    "## 1. DOWNLOAD DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "zoKYKIkzxyzQ",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 16759,
     "status": "ok",
     "timestamp": 1665873224518,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "zoKYKIkzxyzQ",
    "outputId": "27d84869-4ed9-4829-dc4e-1dfc02bdadaf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mounted at /content/drive\n"
     ]
    }
   ],
   "source": [
    "#Mounted in personal files in Drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ff016a14",
   "metadata": {
    "executionInfo": {
     "elapsed": 484,
     "status": "ok",
     "timestamp": 1665873229871,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "ff016a14"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# Initialize dictionary\n",
    "columns={'carat':[],'cut':[],'color':[],'clarity':[],'depth':[],'table':[],'x':[],'y':[],'z':[],'price':[]}\n",
    "\n",
    "# Open CSV file\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/train.csv') as csvfile:\n",
    "    reader = csv.reader(csvfile, delimiter=',')  # Initialize reader\n",
    "    next(reader)                                 # Skip the first line\n",
    "    for row in reader:                           # Append row \n",
    "        for col in range(len(columns)):\n",
    "            columns[list(columns.keys())[col]].append(row[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "715bbede",
   "metadata": {
    "executionInfo": {
     "elapsed": 491,
     "status": "ok",
     "timestamp": 1665873232284,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "715bbede"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.DataFrame.from_dict(columns)       #Convert columns 'dictionary' to DataFrame\n",
    "df = df.astype({\"carat\": np.float64,       #Specify the type of the values\n",
    "                \"depth\":np.float64, \n",
    "                \"table\":np.float64, \n",
    "                \"x\":np.float64, \n",
    "                \"y\":np.float64, \n",
    "                \"z\":np.float64,\n",
    "                \"price\":np.float64})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcfc658f",
   "metadata": {},
   "source": [
    "<a name='2'></a>\n",
    "## 2. CREATE TRAIN/VAL DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e7a84beb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 239,
     "status": "ok",
     "timestamp": 1665873233683,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "e7a84beb",
    "outputId": "bae6005a-363c-43a3-863f-3033ec8b6a52"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-9172df95-b95b-4c82-a83c-b643cadaee6b\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.544971</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "      <td>63.911017</td>\n",
       "      <td>52.575829</td>\n",
       "      <td>5.447452</td>\n",
       "      <td>4.053076</td>\n",
       "      <td>3.701485</td>\n",
       "      <td>3.558</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.073682</td>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>SI1</td>\n",
       "      <td>67.642925</td>\n",
       "      <td>57.660288</td>\n",
       "      <td>6.266665</td>\n",
       "      <td>7.661507</td>\n",
       "      <td>6.177051</td>\n",
       "      <td>24.738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.606198</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "      <td>55.617310</td>\n",
       "      <td>60.388787</td>\n",
       "      <td>6.800151</td>\n",
       "      <td>5.096966</td>\n",
       "      <td>3.480326</td>\n",
       "      <td>3.630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.695397</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "      <td>60.587811</td>\n",
       "      <td>71.325721</td>\n",
       "      <td>5.366931</td>\n",
       "      <td>6.616767</td>\n",
       "      <td>4.454435</td>\n",
       "      <td>4.218</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.282651</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VVS2</td>\n",
       "      <td>68.970056</td>\n",
       "      <td>54.372123</td>\n",
       "      <td>4.920104</td>\n",
       "      <td>4.409408</td>\n",
       "      <td>4.361358</td>\n",
       "      <td>1.578</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-9172df95-b95b-4c82-a83c-b643cadaee6b')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-9172df95-b95b-4c82-a83c-b643cadaee6b button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-9172df95-b95b-4c82-a83c-b643cadaee6b');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      carat      cut color clarity      depth      table         x         y  \\\n",
       "0  0.544971    Ideal     E     SI1  63.911017  52.575829  5.447452  4.053076   \n",
       "1  2.073682  Premium     J     SI1  67.642925  57.660288  6.266665  7.661507   \n",
       "2  0.606198  Premium     G     VS1  55.617310  60.388787  6.800151  5.096966   \n",
       "3  0.695397  Premium     G     SI2  60.587811  71.325721  5.366931  6.616767   \n",
       "4  0.282651    Ideal     E    VVS2  68.970056  54.372123  4.920104  4.409408   \n",
       "\n",
       "          z   price  \n",
       "0  3.701485   3.558  \n",
       "1  6.177051  24.738  \n",
       "2  3.480326   3.630  \n",
       "3  4.454435   4.218  \n",
       "4  4.361358   1.578  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n = len(df)                     #Number of data\n",
    "train_df = df[0:int(n*0.8)]     #Split 80% for training set\n",
    "val_df = df[int(n*0.8):]        #Split the rest of 20% for validation set\n",
    "num_features = df.shape[1]      #Specify the number of features (So far)\n",
    "df.head()                       #Display the first four rows of data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43bdc1b5",
   "metadata": {},
   "source": [
    "<a name='3'></a>\n",
    "## 3. DATA NORMALIZATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01cdf4c8",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "executionInfo": {
     "elapsed": 4,
     "status": "ok",
     "timestamp": 1665873239928,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "01cdf4c8",
    "outputId": "233cb50b-2d8e-49b2-87b0-866a03b502c6"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "  <div id=\"df-bc9e44d4-8b91-4c19-9704-eec1fc26e00c\">\n",
       "    <div class=\"colab-df-container\">\n",
       "      <div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>carat</th>\n",
       "      <th>depth</th>\n",
       "      <th>table</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "      <th>z</th>\n",
       "      <th>price</th>\n",
       "      <th>cut</th>\n",
       "      <th>color</th>\n",
       "      <th>clarity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.118571</td>\n",
       "      <td>0.583269</td>\n",
       "      <td>0.325378</td>\n",
       "      <td>0.470349</td>\n",
       "      <td>0.300980</td>\n",
       "      <td>0.461505</td>\n",
       "      <td>0.078672</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>SI1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.464025</td>\n",
       "      <td>0.673428</td>\n",
       "      <td>0.431509</td>\n",
       "      <td>0.546659</td>\n",
       "      <td>0.667567</td>\n",
       "      <td>0.772820</td>\n",
       "      <td>0.652066</td>\n",
       "      <td>Premium</td>\n",
       "      <td>J</td>\n",
       "      <td>SI1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.132407</td>\n",
       "      <td>0.382902</td>\n",
       "      <td>0.488462</td>\n",
       "      <td>0.596354</td>\n",
       "      <td>0.407031</td>\n",
       "      <td>0.433694</td>\n",
       "      <td>0.080622</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>VS1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.152564</td>\n",
       "      <td>0.502984</td>\n",
       "      <td>0.716755</td>\n",
       "      <td>0.462849</td>\n",
       "      <td>0.561430</td>\n",
       "      <td>0.556193</td>\n",
       "      <td>0.096540</td>\n",
       "      <td>Premium</td>\n",
       "      <td>G</td>\n",
       "      <td>SI2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.059293</td>\n",
       "      <td>0.705491</td>\n",
       "      <td>0.362873</td>\n",
       "      <td>0.421227</td>\n",
       "      <td>0.337180</td>\n",
       "      <td>0.544488</td>\n",
       "      <td>0.025069</td>\n",
       "      <td>Ideal</td>\n",
       "      <td>E</td>\n",
       "      <td>VVS2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>\n",
       "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bc9e44d4-8b91-4c19-9704-eec1fc26e00c')\"\n",
       "              title=\"Convert this dataframe to an interactive table.\"\n",
       "              style=\"display:none;\">\n",
       "        \n",
       "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
       "       width=\"24px\">\n",
       "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
       "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
       "  </svg>\n",
       "      </button>\n",
       "      \n",
       "  <style>\n",
       "    .colab-df-container {\n",
       "      display:flex;\n",
       "      flex-wrap:wrap;\n",
       "      gap: 12px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert {\n",
       "      background-color: #E8F0FE;\n",
       "      border: none;\n",
       "      border-radius: 50%;\n",
       "      cursor: pointer;\n",
       "      display: none;\n",
       "      fill: #1967D2;\n",
       "      height: 32px;\n",
       "      padding: 0 0 0 0;\n",
       "      width: 32px;\n",
       "    }\n",
       "\n",
       "    .colab-df-convert:hover {\n",
       "      background-color: #E2EBFA;\n",
       "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
       "      fill: #174EA6;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert {\n",
       "      background-color: #3B4455;\n",
       "      fill: #D2E3FC;\n",
       "    }\n",
       "\n",
       "    [theme=dark] .colab-df-convert:hover {\n",
       "      background-color: #434B5C;\n",
       "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
       "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
       "      fill: #FFFFFF;\n",
       "    }\n",
       "  </style>\n",
       "\n",
       "      <script>\n",
       "        const buttonEl =\n",
       "          document.querySelector('#df-bc9e44d4-8b91-4c19-9704-eec1fc26e00c button.colab-df-convert');\n",
       "        buttonEl.style.display =\n",
       "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
       "\n",
       "        async function convertToInteractive(key) {\n",
       "          const element = document.querySelector('#df-bc9e44d4-8b91-4c19-9704-eec1fc26e00c');\n",
       "          const dataTable =\n",
       "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
       "                                                     [key], {});\n",
       "          if (!dataTable) return;\n",
       "\n",
       "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
       "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
       "            + ' to learn more about interactive tables.';\n",
       "          element.innerHTML = '';\n",
       "          dataTable['output_type'] = 'display_data';\n",
       "          await google.colab.output.renderOutput(dataTable, element);\n",
       "          const docLink = document.createElement('div');\n",
       "          docLink.innerHTML = docLinkHtml;\n",
       "          element.appendChild(docLink);\n",
       "        }\n",
       "      </script>\n",
       "    </div>\n",
       "  </div>\n",
       "  "
      ],
      "text/plain": [
       "      carat     depth     table         x         y         z     price  \\\n",
       "0  0.118571  0.583269  0.325378  0.470349  0.300980  0.461505  0.078672   \n",
       "1  0.464025  0.673428  0.431509  0.546659  0.667567  0.772820  0.652066   \n",
       "2  0.132407  0.382902  0.488462  0.596354  0.407031  0.433694  0.080622   \n",
       "3  0.152564  0.502984  0.716755  0.462849  0.561430  0.556193  0.096540   \n",
       "4  0.059293  0.705491  0.362873  0.421227  0.337180  0.544488  0.025069   \n",
       "\n",
       "       cut color clarity  \n",
       "0    Ideal     E     SI1  \n",
       "1  Premium     J     SI1  \n",
       "2  Premium     G     VS1  \n",
       "3  Premium     G     SI2  \n",
       "4    Ideal     E    VVS2  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a new DataFrame with only the columns with type \"number\" data\n",
    "df_num = train_df.select_dtypes('number')\n",
    "\n",
    "#Obtain the min / max value from the previous DataFrame\n",
    "train_min = train_df.min(numeric_only=True)\n",
    "train_max = train_df.max(numeric_only=True)\n",
    "\n",
    "#Data normalization with the min / max values\n",
    "norm_train=(train_df[df_num.columns] - train_min) / (train_max-train_min)\n",
    "norm_val=(val_df[df_num.columns] - train_min) / (train_max-train_min)\n",
    "\n",
    "#Save the values from min / max prices, to use in the future for data de-normalization\n",
    "min_price=train_min['price']\n",
    "max_price=train_max['price']\n",
    "\n",
    "#Create the normalized data with the previous values\n",
    "norm_train=norm_train.join(train_df[['cut','color','clarity']])\n",
    "norm_val=norm_val.join(val_df[['cut','color','clarity']])\n",
    "\n",
    "#Check the first rowns from the Normalized DataFrame\n",
    "norm_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c1385c2",
   "metadata": {},
   "source": [
    "<a name='4'></a>\n",
    "## 4. ONE-HOT ENCODING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4816a59e",
   "metadata": {
    "executionInfo": {
     "elapsed": 234,
     "status": "ok",
     "timestamp": 1665873241929,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "4816a59e"
   },
   "outputs": [],
   "source": [
    "#Use \"get_dummies\" to obtain the \"one-hot\" encoding from the strings columns\n",
    "train_features = pd.get_dummies(norm_train).drop('price', axis=1)\n",
    "val_features = pd.get_dummies(norm_val).drop('price', axis=1)\n",
    "\n",
    "#Separate the columns of the prices and save as the labels\n",
    "train_labels = norm_train['price']\n",
    "val_labels = norm_val['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd08eeb5",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "## 5. CREATE DATASET (TensorFlow)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "94e4b8e6",
   "metadata": {
    "executionInfo": {
     "elapsed": 5313,
     "status": "ok",
     "timestamp": 1665873250608,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "94e4b8e6"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "# Turn our data into TensorFlow Datasets\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices((train_features, tf.expand_dims(train_labels,axis=1) ))\n",
    "valid_dataset = tf.data.Dataset.from_tensor_slices((val_features, tf.expand_dims(val_labels,axis=1) ))\n",
    "\n",
    "# Take the TensorSliceDataset's and turn them into prefetched batches\n",
    "train_dataset = train_dataset.batch(32).prefetch(tf.data.AUTOTUNE)\n",
    "valid_dataset = valid_dataset.batch(32).prefetch(tf.data.AUTOTUNE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32d4f24a",
   "metadata": {},
   "source": [
    "<a name='6'></a>\n",
    "## 6. CREATE PERSONAL CALLBACK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "aef003d9",
   "metadata": {
    "executionInfo": {
     "elapsed": 5,
     "status": "ok",
     "timestamp": 1665873250609,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "aef003d9"
   },
   "outputs": [],
   "source": [
    "def Personal_callback(model_name, metrics, threshold_metric, ep, lr_i=0.001):\n",
    "    \"\"\"Generate a list of personal Callbacks to use in the training process\n",
    "    Args:\n",
    "        model_name (string)        - Contain the name of the model\n",
    "        metrics (string)           - Contains the metric to be evaluated\n",
    "        threshold_metric (string)  - Specify the threshold for the metric\n",
    "        ep (int)                   - The number of epoch in the training process\n",
    "        lr_i                       - Specify the initial learning rate\n",
    "        \n",
    "    Returns:\n",
    "        A list of callback functions to use in the training process\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "    Stop training\n",
    "    \"\"\"\n",
    "    class stop_training(tf.keras.callbacks.Callback):                                               #Define the class\n",
    "        def on_epoch_end(self, epoch, logs = {}):                                                   #Use in the end of the epoch\n",
    "            if(logs.get(metrics)<threshold_metric and logs.get('val_'+metrics) <threshold_metric):  #Define threshold for metrics\n",
    "                print(\"\\Cancelling training!\")\n",
    "                self.model.stop_training = True                                                     #Stop the training process\n",
    "    stop_train = stop_training()\n",
    "    \n",
    "    \"\"\"\n",
    "    Learning Rate Decay\n",
    "    \"\"\"\n",
    "    global LR_init        #Define global variable\n",
    "    LR_init=lr_i          #Specify the initial learning rate\n",
    "    \n",
    "    class learning_decay(tf.keras.callbacks.Callback):                        #Define the class\n",
    "        def on_epoch_end(self, batch, logs={}):                               #Use in the end of the epoch\n",
    "            lr = self.model.optimizer.lr                                      #Call the leraning rate from the model\n",
    "            global LR_init                                                    #Define global variable\n",
    "            new_lr = (LR_init) * 10.**(-(batch+1.)/(ep*10))                   #Define the learning rate decay function\n",
    "            if lr > new_lr:                                                   #If the previous lr is greater than actual lr \n",
    "                tf.keras.backend.set_value(self.model.optimizer.lr, new_lr)   #Update the value of the learning rate\n",
    "            else: \n",
    "                LR_init=lr                                                    #This used because we use the callback 'ReduceLROnPlateau'\n",
    "\n",
    "    lr_decay = learning_decay()\n",
    "    \n",
    "    \"\"\"\n",
    "    Reduce Learning Rate\n",
    "    \"\"\"\n",
    "    # Creating learning rate reduction callback\n",
    "    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor= metrics,   #Specify the metrics\n",
    "                                                     factor=0.2,         # new_lr = lr * factor\n",
    "                                                     patience=2,         # number of epochs with no improvement after which learning rate will be reduced\n",
    "                                                     verbose=1,          # print out when learning rate goes down \n",
    "                                                     min_lr=1e-15)       # lower bound on the learning rate\n",
    "    \"\"\"\n",
    "    Early Stopping\n",
    "    \"\"\"\n",
    "    # Setup EarlyStopping callback to stop training if model's val_loss doesn't improve for 10 epochs\n",
    "    early_stopping = tf.keras.callbacks.EarlyStopping(monitor = metrics,         # watch the val loss metric\n",
    "                                                  patience = 10,                 # if val loss decreases for 3 epochs in a row, stop training\n",
    "                                                  min_delta = 0.00001,           # Minimum change in the monitored quantity to qualify as an improvement\n",
    "                                                  restore_best_weights = False,  #Don't sabe the best weights, because we use the callback \"ModelCheckpoint\"\n",
    "                                                     verbose=1)                  #Display a message\n",
    "    \"\"\"\n",
    "    Model Checkpoint - Train metrics\n",
    "    \"\"\"\n",
    "    # Create ModelCheckpoint callback to save model's progress\n",
    "    chk_train_path = \"checkpoint_path/\"+ model_name +\"/train/chk_train.ckpt\"      # saving weights requires \".ckpt\" extension\n",
    "    chk_train = tf.keras.callbacks.ModelCheckpoint(filepath=chk_train_path,\n",
    "                                                         monitor=metrics,         # save the model weights with best metric\n",
    "                                                         save_weights_only=True,  # set to False to save the entire model\n",
    "                                                         save_best_only=True,     # set to True to save only the best model instead of a model every epoch \n",
    "                                                         save_freq=\"epoch\",       # save every epoch\n",
    "                                                         verbose=0)               # don't print out whether or not model is being saved \n",
    "    \n",
    "    \"\"\"\n",
    "    Model Checkpoint - Train metrics\n",
    "    \"\"\"\n",
    "    # Create ModelCheckpoint callback to save model's progress\n",
    "    chk_val_path = \"checkpoint_path/\"+ model_name +\"/val/chk_val.ckpt\"             # saving weights requires \".ckpt\" extension\n",
    "    chk_val = tf.keras.callbacks.ModelCheckpoint(filepath=chk_val_path,\n",
    "                                                         monitor='val_'+metrics,   # save the model weights with best validation metric\n",
    "                                                         save_weights_only=True,   # set to False to save the entire model\n",
    "                                                         save_best_only=True,      # set to True to save only the best model instead of a model every epoch \n",
    "                                                         save_freq=\"epoch\",        # save every epoch\n",
    "                                                         verbose=0)                # don't print out whether or not model is being saved \n",
    "    \n",
    "    return [stop_train, lr_decay, reduce_lr, early_stopping, chk_train, chk_val]   #Return a list of Callbacks"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a378e98",
   "metadata": {},
   "source": [
    "<a name='7'></a>\n",
    "## 7. BUILD AND COMPILE THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "80c2e680",
   "metadata": {
    "executionInfo": {
     "elapsed": 1878,
     "status": "ok",
     "timestamp": 1665874206549,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "80c2e680"
   },
   "outputs": [],
   "source": [
    "#BUILD THE MODEL\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Input(shape=(26,)),                                               #Define Input: 26 features\n",
    "    tf.keras.layers.Lambda(lambda x: tf.expand_dims(x, axis=1)),                      #Expand the dimension\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(182, return_sequences=True)),  #Use Bidirectional LSTM\n",
    "    tf.keras.layers.Dropout(0.4),                                                     #Dropout to reduce overfitting\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(150, return_sequences=True)),  #Use Bidirectional LSTM\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(128, return_sequences=True)),  #Use Bidirectional LSTM\n",
    "    tf.keras.layers.Dense(units=32, activation=\"relu\"),                               #Use Dense layer\n",
    "    tf.keras.layers.Dense(units=16, activation=\"relu\"),                               #Use Dense layer\n",
    "    tf.keras.layers.Dense(units=1, activation=\"relu\"),                                #Use Dense layer for OUTPUT\n",
    "    tf.keras.layers.Reshape([1, -1])                                                  #Reshape the output\n",
    "])\n",
    "\n",
    "#COMPILE THE MODEL\n",
    "model.compile(loss='mse',                      #Define the loss: Mean Squared Error\n",
    "              optimizer=tf.optimizers.Adam(),  #Define the optimizer\n",
    "              metrics=['mae'])                 #Define the metrics\n",
    "\n",
    "#SAVE THE INITIAL WEIGHTS (Use when try with different models)\n",
    "InitialW = model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1a4779",
   "metadata": {},
   "source": [
    "<a name='8'></a>\n",
    "## 8. FIT THE MODEL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "9700988d",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 306805,
     "status": "ok",
     "timestamp": 1665874515778,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "9700988d",
    "outputId": "3c5a620a-59d8-4e98-a947-2564a2049e85",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "300/300 [==============================] - 15s 20ms/step - loss: 0.0147 - mae: 0.0781 - val_loss: 0.0055 - val_mae: 0.0464 - lr: 9.9770e-04\n",
      "Epoch 2/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0062 - mae: 0.0519 - val_loss: 0.0039 - val_mae: 0.0406 - lr: 9.9541e-04\n",
      "Epoch 3/100\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.0049 - mae: 0.0462 - val_loss: 0.0039 - val_mae: 0.0415 - lr: 9.9312e-04\n",
      "Epoch 4/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0042 - mae: 0.0430 - val_loss: 0.0036 - val_mae: 0.0412 - lr: 9.9083e-04\n",
      "Epoch 5/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0040 - mae: 0.0419 - val_loss: 0.0035 - val_mae: 0.0406 - lr: 9.8855e-04\n",
      "Epoch 6/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0038 - mae: 0.0413 - val_loss: 0.0033 - val_mae: 0.0383 - lr: 9.8628e-04\n",
      "Epoch 7/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0037 - mae: 0.0408 - val_loss: 0.0032 - val_mae: 0.0390 - lr: 9.8401e-04\n",
      "Epoch 8/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0036 - mae: 0.0402 - val_loss: 0.0032 - val_mae: 0.0379 - lr: 9.8175e-04\n",
      "Epoch 9/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0036 - mae: 0.0396 - val_loss: 0.0030 - val_mae: 0.0370 - lr: 9.7949e-04\n",
      "Epoch 10/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0035 - mae: 0.0394 - val_loss: 0.0031 - val_mae: 0.0390 - lr: 9.7724e-04\n",
      "Epoch 11/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0034 - mae: 0.0387 - val_loss: 0.0032 - val_mae: 0.0404 - lr: 9.7499e-04\n",
      "Epoch 12/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0033 - mae: 0.0383 - val_loss: 0.0030 - val_mae: 0.0382 - lr: 9.7275e-04\n",
      "Epoch 13/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0033 - mae: 0.0382 - val_loss: 0.0032 - val_mae: 0.0381 - lr: 9.7051e-04\n",
      "Epoch 14/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0033 - mae: 0.0380 - val_loss: 0.0033 - val_mae: 0.0408 - lr: 9.6828e-04\n",
      "Epoch 15/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0032 - mae: 0.0381 - val_loss: 0.0029 - val_mae: 0.0363 - lr: 9.6605e-04\n",
      "Epoch 16/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0032 - mae: 0.0378 - val_loss: 0.0029 - val_mae: 0.0361 - lr: 9.6383e-04\n",
      "Epoch 17/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0032 - mae: 0.0374 - val_loss: 0.0031 - val_mae: 0.0363 - lr: 9.6161e-04\n",
      "Epoch 18/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0031 - mae: 0.0371 - val_loss: 0.0034 - val_mae: 0.0404 - lr: 9.5940e-04\n",
      "Epoch 19/100\n",
      "300/300 [==============================] - 4s 12ms/step - loss: 0.0031 - mae: 0.0372 - val_loss: 0.0031 - val_mae: 0.0390 - lr: 9.5719e-04\n",
      "Epoch 20/100\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.0032 - mae: 0.0377\n",
      "Epoch 20: ReduceLROnPlateau reducing learning rate to 0.00019099852070212365.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0032 - mae: 0.0377 - val_loss: 0.0029 - val_mae: 0.0352 - lr: 9.5499e-04\n",
      "Epoch 21/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0027 - mae: 0.0345 - val_loss: 0.0027 - val_mae: 0.0333 - lr: 1.9100e-04\n",
      "Epoch 22/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0026 - mae: 0.0338 - val_loss: 0.0027 - val_mae: 0.0331 - lr: 1.8156e-04\n",
      "Epoch 23/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0026 - mae: 0.0337 - val_loss: 0.0027 - val_mae: 0.0332 - lr: 1.7220e-04\n",
      "Epoch 24/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0026 - mae: 0.0336 - val_loss: 0.0027 - val_mae: 0.0331 - lr: 1.6294e-04\n",
      "Epoch 25/100\n",
      "300/300 [==============================] - 5s 16ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0028 - val_mae: 0.0339 - lr: 1.5383e-04\n",
      "Epoch 26/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0027 - val_mae: 0.0331 - lr: 1.4489e-04\n",
      "Epoch 27/100\n",
      "298/300 [============================>.] - ETA: 0s - loss: 0.0026 - mae: 0.0335\n",
      "Epoch 27: ReduceLROnPlateau reducing learning rate to 2.723077195696533e-05.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0026 - mae: 0.0334 - val_loss: 0.0027 - val_mae: 0.0330 - lr: 1.3615e-04\n",
      "Epoch 28/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0330 - val_loss: 0.0026 - val_mae: 0.0325 - lr: 2.5531e-05\n",
      "Epoch 29/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0026 - val_mae: 0.0326 - lr: 2.3881e-05\n",
      "Epoch 30/100\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0026 - val_mae: 0.0325 - lr: 2.2287e-05\n",
      "Epoch 31/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0324 - lr: 2.0752e-05\n",
      "Epoch 32/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0026 - val_mae: 0.0325 - lr: 1.9278e-05\n",
      "Epoch 33/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0026 - val_mae: 0.0324 - lr: 1.7867e-05\n",
      "Epoch 34/100\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0329\n",
      "Epoch 34: ReduceLROnPlateau reducing learning rate to 3.30437978846021e-06.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0026 - val_mae: 0.0325 - lr: 1.6522e-05\n",
      "Epoch 35/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 3.0485e-06\n",
      "Epoch 36/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0327\n",
      "Epoch 36: ReduceLROnPlateau reducing learning rate to 5.61202978133224e-07.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 2.8060e-06\n",
      "Epoch 37/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 5.1537e-07\n",
      "Epoch 38/100\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.0024 - mae: 0.0325\n",
      "Epoch 38: ReduceLROnPlateau reducing learning rate to 9.44386897572258e-08.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 4.7219e-07\n",
      "Epoch 39/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 8.6328e-08\n",
      "Epoch 40/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0328\n",
      "Epoch 40: ReduceLROnPlateau reducing learning rate to 1.5746351778034295e-08.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 7.8732e-08\n",
      "Epoch 41/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 1.4328e-08\n",
      "Epoch 42/100\n",
      "296/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0328\n",
      "Epoch 42: ReduceLROnPlateau reducing learning rate to 2.6014168597043863e-09.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 1.3007e-08\n",
      "Epoch 43/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 2.3562e-09\n",
      "Epoch 44/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0326\n",
      "Epoch 44: ReduceLROnPlateau reducing learning rate to 4.2583359061154624e-10.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 2.1292e-09\n",
      "Epoch 45/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 3.8392e-10\n",
      "Epoch 46/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0025 - mae: 0.0327\n",
      "Epoch 46: ReduceLROnPlateau reducing learning rate to 6.906689109520414e-11.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 3.4533e-10\n",
      "Epoch 47/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 6.1983e-11\n",
      "Epoch 48/100\n",
      "300/300 [==============================] - 5s 15ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 5.5497e-11\n",
      "Epoch 49/100\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0325\n",
      "Epoch 49: ReduceLROnPlateau reducing learning rate to 9.91516452275576e-12.\n",
      "300/300 [==============================] - 4s 14ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 4.9576e-11\n",
      "Epoch 50/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 8.8369e-12\n",
      "Epoch 51/100\n",
      "300/300 [==============================] - ETA: 0s - loss: 0.0024 - mae: 0.0324\n",
      "Epoch 51: ReduceLROnPlateau reducing learning rate to 1.571556079715819e-12.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 7.8578e-12\n",
      "Epoch 52/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 1.3942e-12\n",
      "Epoch 53/100\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0327\n",
      "Epoch 53: ReduceLROnPlateau reducing learning rate to 2.4680836801377336e-13.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 1.2340e-12\n",
      "Epoch 54/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 2.1795e-13\n",
      "Epoch 55/100\n",
      "297/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0327\n",
      "Epoch 55: ReduceLROnPlateau reducing learning rate to 3.840518669143839e-14.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0327 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 1.9203e-13\n",
      "Epoch 56/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0323 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 3.3759e-14\n",
      "Epoch 57/100\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0326\n",
      "Epoch 57: ReduceLROnPlateau reducing learning rate to 5.921338316590766e-15.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 2.9607e-14\n",
      "Epoch 58/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 5.1811e-15\n",
      "Epoch 59/100\n",
      "299/300 [============================>.] - ETA: 0s - loss: 0.0025 - mae: 0.0325\n",
      "Epoch 59: ReduceLROnPlateau reducing learning rate to 1e-15.\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 4.5229e-15\n",
      "Epoch 60/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 8.7096e-16\n",
      "Epoch 61/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0325 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 7.5683e-16\n",
      "Epoch 62/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0329 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 6.5615e-16\n",
      "Epoch 63/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0024 - mae: 0.0324 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 5.6754e-16\n",
      "Epoch 64/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 4.8978e-16\n",
      "Epoch 65/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0326 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 4.2170e-16\n",
      "Epoch 66/100\n",
      "300/300 [==============================] - 4s 13ms/step - loss: 0.0025 - mae: 0.0328 - val_loss: 0.0025 - val_mae: 0.0323 - lr: 3.6224e-16\n",
      "Epoch 66: early stopping\n"
     ]
    }
   ],
   "source": [
    "#Load the initial weights\n",
    "model.set_weights(InitialW)\n",
    "\n",
    "#Reset the value of learning rate in the model\n",
    "tf.keras.backend.set_value(model.optimizer.lr, 0.001)\n",
    "\n",
    "#Fit the model\n",
    "history = model.fit(train_dataset, \n",
    "                    epochs=100,\n",
    "                    validation_data=valid_dataset,\n",
    "                    callbacks=Personal_callback(model_name='model/FIT_1', \n",
    "                                                metrics='mae', \n",
    "                                                threshold_metric=0.02,\n",
    "                                                ep=100)\n",
    "                   )\n",
    "\n",
    "#Save the model weights (Use when you train again)\n",
    "FIT_1=model.get_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c911b1e",
   "metadata": {},
   "source": [
    "<a name='9'></a>\n",
    "## 9. SAVE THE BEST RESULT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "fc4bbceb",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 5706,
     "status": "ok",
     "timestamp": 1665874558131,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "fc4bbceb",
    "outputId": "a44dc2e3-f734-4345-863f-a4bce5ccc7ea"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "75/75 [==============================] - 4s 6ms/step - loss: 0.0025 - mae: 0.0323\n"
     ]
    }
   ],
   "source": [
    "#Clone the model\n",
    "model_load = tf.keras.models.clone_model(model)\n",
    "\n",
    "#Re-define: Compile Model\n",
    "model_load.compile(loss='mse',\n",
    "                  optimizer=tf.optimizers.Adam(),\n",
    "                  metrics=['mae'])\n",
    "\n",
    "#Load the weights from the best results in the train metrics\n",
    "model_load.load_weights(\"checkpoint_path/model/FIT_1/train/chk_train.ckpt\")\n",
    "\n",
    "#Evaluate the model with the validation dataset\n",
    "load_evaluate=model_load.evaluate(valid_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "b735b99a",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 7135,
     "status": "ok",
     "timestamp": 1665874681252,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "b735b99a",
    "outputId": "fe2f38f0-0f90-4138-864e-37ce3031ee7a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "300/300 [==============================] - 5s 6ms/step - loss: 0.0023 - mae: 0.0311\n"
     ]
    }
   ],
   "source": [
    "#Evaluate the model with the training dataset\n",
    "load_evaluate=model_load.evaluate(train_dataset, batch_size=32)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58ea1f5b",
   "metadata": {
    "id": "58ea1f5b"
   },
   "source": [
    "<a name='10'></a>\n",
    "## 10. GENERATE ASSIGMENT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "88f6bb85",
   "metadata": {
    "executionInfo": {
     "elapsed": 311,
     "status": "ok",
     "timestamp": 1665874541982,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "88f6bb85"
   },
   "outputs": [],
   "source": [
    "import csv\n",
    "# Initialize dictionary\n",
    "columns={'carat':[],'cut':[],'color':[],'clarity':[],'depth':[],'table':[],'x':[],'y':[],'z':[]}\n",
    "\n",
    "# Open CSV file from test file\n",
    "with open('/content/drive/MyDrive/Colab Notebooks/test.csv') as csvfile: \n",
    "    reader = csv.reader(csvfile, delimiter=',')      # Initialize reader\n",
    "    next(reader)                                     # Skip the first line\n",
    "    for row in reader:\n",
    "        for col in range(len(columns)):\n",
    "            columns[list(columns.keys())[col]].append(row[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "520913c6",
   "metadata": {
    "executionInfo": {
     "elapsed": 264,
     "status": "ok",
     "timestamp": 1665874544848,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "520913c6"
   },
   "outputs": [],
   "source": [
    "subm = pd.DataFrame.from_dict(columns)     #Convert columns 'dictionary' to DataFrame\n",
    "subm = subm.astype({\"carat\": np.float64,   #Specify the type of the values\n",
    "                \"depth\":np.float64, \n",
    "                \"table\":np.float64, \n",
    "                \"x\":np.float64, \n",
    "                \"y\":np.float64, \n",
    "                \"z\":np.float64})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "adfaa7a5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 14307,
     "status": "ok",
     "timestamp": 1665874572431,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "adfaa7a5",
    "outputId": "a69e4b61-010c-4b58-eb02-e44334a7e877"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3000/3000 [==============================] - 14s 4ms/step\n"
     ]
    }
   ],
   "source": [
    "#Create a new DataFrame with only the columns with type \"number\" data\n",
    "df_num = train_df.select_dtypes('number')\n",
    "\n",
    "#Obtain the min / max value from the Training DataFrame (Drop the colum of 'Price')\n",
    "train_max = train_df.drop('price', axis=1).max(numeric_only=True)\n",
    "train_min = train_df.drop('price', axis=1).min(numeric_only=True)\n",
    "\n",
    "#Test data normalization with min/max values of the training dataset\n",
    "norm_subm = (subm[df_num.columns[:-1]] - train_min) / (train_max-train_min)\n",
    "\n",
    "#Create the normalized data with the previous values\n",
    "norm_subm = norm_subm.join(subm[['cut','color','clarity']])\n",
    "\n",
    "#Use \"get_dummies\" to obtain the \"one-hot\" encoding from the strings columns\n",
    "subm_features = pd.get_dummies(norm_subm)\n",
    "\n",
    "# Turn our data into TensorFlow Datasets\n",
    "subm_dataset = tf.data.Dataset.from_tensor_slices(subm_features)\n",
    "subm_dataset = subm_dataset.batch(1, drop_remainder=True).prefetch(1)\n",
    "\n",
    "#Predict the target values using the previous test dataset and the load model\n",
    "x=model_load.predict(subm_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "14c80196",
   "metadata": {
    "executionInfo": {
     "elapsed": 20,
     "status": "ok",
     "timestamp": 1665874572432,
     "user": {
      "displayName": "José Mejía Gamarra",
      "userId": "00754235627654071738"
     },
     "user_tz": 300
    },
    "id": "14c80196"
   },
   "outputs": [],
   "source": [
    "#Removes dimensions of size 1 from the shape of a tensor\n",
    "x=np.squeeze(x)\n",
    "\n",
    "#De-normalize the output values (using the min/max 'price' values in the training dataset)\n",
    "subm_prices=x*(max_price-min_price)+min_price\n",
    "\n",
    "#Define a list of arange \n",
    "id_subm=np.arange(start=0, stop=len(subm_prices))\n",
    "\n",
    "#Define a dictionary with the correspond values\n",
    "dict_subm={'id':id_subm, 'price':subm_prices}\n",
    "\n",
    "#Convert the dictionary to DataFrame\n",
    "df_subm = pd.DataFrame.from_dict(dict_subm)\n",
    "\n",
    "#Set the index column\n",
    "df_subm=df_subm.set_index('id')\n",
    "\n",
    "#Save the DataFrame as .csv file\n",
    "df_subm.to_csv('/content/drive/MyDrive/Colab Notebooks/subm.zip') "
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
